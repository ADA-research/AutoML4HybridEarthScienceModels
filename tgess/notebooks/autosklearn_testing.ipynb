{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8bda9f",
   "metadata": {},
   "source": [
    "Testing autosklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78848e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/pyparsing.py:3190: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0367dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/processed/PROSAIL_LUT_S2_10000_generic.csv\")\n",
    "validation_df = pd.read_csv(\"../data/processed/GBOV_RM07_in_situ_train.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/GBOV_RM07_in_situ_holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be06d7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Site</th>\n",
       "      <th>date</th>\n",
       "      <th>plotID</th>\n",
       "      <th>retrieval_date</th>\n",
       "      <th>LAI_Miller</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>...</th>\n",
       "      <th>QA20</th>\n",
       "      <th>QA60</th>\n",
       "      <th>cloud_probability</th>\n",
       "      <th>nlcdClass</th>\n",
       "      <th>observer_azimuth</th>\n",
       "      <th>observer_zenith</th>\n",
       "      <th>solar_zenith</th>\n",
       "      <th>solar_azimuth</th>\n",
       "      <th>relative_azimuth</th>\n",
       "      <th>LAI_Warren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "      <td>LajasExperimentalStation</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>LAJA_065</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1.3800</td>\n",
       "      <td>0.065434</td>\n",
       "      <td>0.070778</td>\n",
       "      <td>0.095199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>pastureHay</td>\n",
       "      <td>102.478875</td>\n",
       "      <td>7.775917</td>\n",
       "      <td>41.609523</td>\n",
       "      <td>155.574434</td>\n",
       "      <td>53.095558</td>\n",
       "      <td>1.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2758</td>\n",
       "      <td>2758</td>\n",
       "      <td>Underc</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>UNDE_048</td>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>2.1020</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.035183</td>\n",
       "      <td>0.054432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mixedForest</td>\n",
       "      <td>286.090525</td>\n",
       "      <td>8.047912</td>\n",
       "      <td>26.637376</td>\n",
       "      <td>156.032280</td>\n",
       "      <td>229.941755</td>\n",
       "      <td>2.3860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>LajasExperimentalStation</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>LAJA_065</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.037561</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.066380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pastureHay</td>\n",
       "      <td>101.824467</td>\n",
       "      <td>7.872103</td>\n",
       "      <td>43.392796</td>\n",
       "      <td>145.979591</td>\n",
       "      <td>44.155124</td>\n",
       "      <td>0.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>Jornada</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>JORN_053</td>\n",
       "      <td>2016-07-23</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.097069</td>\n",
       "      <td>0.136192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>shrubScrub</td>\n",
       "      <td>104.584100</td>\n",
       "      <td>6.829718</td>\n",
       "      <td>21.688155</td>\n",
       "      <td>122.220188</td>\n",
       "      <td>17.636088</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>NorthSterling</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>STER_014</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.094235</td>\n",
       "      <td>0.117358</td>\n",
       "      <td>0.150066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cultivatedCrops</td>\n",
       "      <td>211.664295</td>\n",
       "      <td>3.102768</td>\n",
       "      <td>26.866117</td>\n",
       "      <td>148.780685</td>\n",
       "      <td>297.116390</td>\n",
       "      <td>0.0570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2465</td>\n",
       "      <td>2465</td>\n",
       "      <td>SteigerwaldtLandServices</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>STEI_058</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>0.029406</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>deciduousForest</td>\n",
       "      <td>287.497226</td>\n",
       "      <td>8.950586</td>\n",
       "      <td>50.697639</td>\n",
       "      <td>168.157560</td>\n",
       "      <td>240.660334</td>\n",
       "      <td>3.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>1084</td>\n",
       "      <td>1084</td>\n",
       "      <td>NorthSterling</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>STER_014</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>0.100679</td>\n",
       "      <td>0.105116</td>\n",
       "      <td>0.127461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>cultivatedCrops</td>\n",
       "      <td>265.434501</td>\n",
       "      <td>2.434298</td>\n",
       "      <td>33.393639</td>\n",
       "      <td>151.842781</td>\n",
       "      <td>246.408281</td>\n",
       "      <td>1.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>OnaquiAult</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>ONAQ_069</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>shrubScrub</td>\n",
       "      <td>104.229795</td>\n",
       "      <td>9.448723</td>\n",
       "      <td>47.125692</td>\n",
       "      <td>160.904504</td>\n",
       "      <td>56.674709</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>1563</td>\n",
       "      <td>1563</td>\n",
       "      <td>OrdwaySwisherBiologicalStation</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>OSBS_025</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.035055</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>evergreenForest</td>\n",
       "      <td>102.954880</td>\n",
       "      <td>7.695383</td>\n",
       "      <td>52.769160</td>\n",
       "      <td>153.942963</td>\n",
       "      <td>50.988083</td>\n",
       "      <td>0.5662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>2338</td>\n",
       "      <td>2338</td>\n",
       "      <td>SteigerwaldtLandServices</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>STEI_046</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>1.1320</td>\n",
       "      <td>0.017679</td>\n",
       "      <td>0.018528</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>deciduousForest</td>\n",
       "      <td>101.839977</td>\n",
       "      <td>4.958994</td>\n",
       "      <td>57.422227</td>\n",
       "      <td>167.654014</td>\n",
       "      <td>65.814037</td>\n",
       "      <td>1.2090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2102 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1                            Site        date  \\\n",
       "0            607           607        LajasExperimentalStation  2016-11-23   \n",
       "1           2758          2758                          Underc  2017-05-23   \n",
       "2            611           611        LajasExperimentalStation  2017-02-10   \n",
       "3            233           233                         Jornada  2016-07-27   \n",
       "4           1087          1087                   NorthSterling  2016-05-11   \n",
       "...          ...           ...                             ...         ...   \n",
       "2097        2465          2465        SteigerwaldtLandServices  2018-10-04   \n",
       "2098        1084          1084                   NorthSterling  2015-09-02   \n",
       "2099        1471          1471                      OnaquiAult  2015-09-23   \n",
       "2100        1563          1563  OrdwaySwisherBiologicalStation  2018-02-01   \n",
       "2101        2338          2338        SteigerwaldtLandServices  2015-10-27   \n",
       "\n",
       "        plotID retrieval_date  LAI_Miller        B1        B2        B3  ...  \\\n",
       "0     LAJA_065     2016-11-19      1.3800  0.065434  0.070778  0.095199  ...   \n",
       "1     UNDE_048     2017-05-27      2.1020  0.032707  0.035183  0.054432  ...   \n",
       "2     LAJA_065     2017-01-28      0.9200  0.037561  0.036632  0.066380  ...   \n",
       "3     JORN_053     2016-07-23      0.0034  0.077465  0.097069  0.136192  ...   \n",
       "4     STER_014     2016-05-04      0.0371  0.094235  0.117358  0.150066  ...   \n",
       "...        ...            ...         ...       ...       ...       ...  ...   \n",
       "2097  STEI_058     2018-10-04      3.7610  0.029406  0.032106  0.052885  ...   \n",
       "2098  STER_014     2015-08-28      1.1200  0.100679  0.105116  0.127461  ...   \n",
       "2099  ONAQ_069     2015-10-06      0.0093  0.063949  0.052577  0.052016  ...   \n",
       "2100  OSBS_025     2018-01-24      0.7257  0.018663  0.035055  0.053114  ...   \n",
       "2101  STEI_046     2015-10-22      1.1320  0.017679  0.018528  0.027429  ...   \n",
       "\n",
       "      QA20  QA60  cloud_probability        nlcdClass  observer_azimuth  \\\n",
       "0      0.0   0.0               16.0       pastureHay        102.478875   \n",
       "1      0.0   0.0                1.0      mixedForest        286.090525   \n",
       "2      0.0   0.0                4.0       pastureHay        101.824467   \n",
       "3      0.0   0.0                2.0       shrubScrub        104.584100   \n",
       "4      0.0   0.0                1.0  cultivatedCrops        211.664295   \n",
       "...    ...   ...                ...              ...               ...   \n",
       "2097   0.0   0.0                3.0  deciduousForest        287.497226   \n",
       "2098   0.0   0.0               23.0  cultivatedCrops        265.434501   \n",
       "2099   0.0   0.0               30.0       shrubScrub        104.229795   \n",
       "2100   0.0   0.0                3.0  evergreenForest        102.954880   \n",
       "2101   0.0   0.0                2.0  deciduousForest        101.839977   \n",
       "\n",
       "      observer_zenith  solar_zenith  solar_azimuth  relative_azimuth  \\\n",
       "0            7.775917     41.609523     155.574434         53.095558   \n",
       "1            8.047912     26.637376     156.032280        229.941755   \n",
       "2            7.872103     43.392796     145.979591         44.155124   \n",
       "3            6.829718     21.688155     122.220188         17.636088   \n",
       "4            3.102768     26.866117     148.780685        297.116390   \n",
       "...               ...           ...            ...               ...   \n",
       "2097         8.950586     50.697639     168.157560        240.660334   \n",
       "2098         2.434298     33.393639     151.842781        246.408281   \n",
       "2099         9.448723     47.125692     160.904504         56.674709   \n",
       "2100         7.695383     52.769160     153.942963         50.988083   \n",
       "2101         4.958994     57.422227     167.654014         65.814037   \n",
       "\n",
       "      LAI_Warren  \n",
       "0         1.0600  \n",
       "1         2.3860  \n",
       "2         0.6200  \n",
       "3         0.0021  \n",
       "4         0.0570  \n",
       "...          ...  \n",
       "2097      3.2920  \n",
       "2098      1.5000  \n",
       "2099      0.0120  \n",
       "2100      0.5662  \n",
       "2101      1.2090  \n",
       "\n",
       "[2102 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a0c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={\"lai\":\"LAI_Warren\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30df6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce8f6c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    alpha, Type: UniformFloat, Range: [1e-05, 1.0], Default: 1.0, on log-scale\n",
      "    coef0, Type: UniformFloat, Range: [0.01, 100.0], Default: 1.0, on log-scale\n",
      "    degree, Type: UniformInteger, Range: [2, 5], Default: 3\n",
      "    gamma, Type: UniformFloat, Range: [1e-05, 1.0], Default: 0.1, on log-scale\n",
      "    kernel, Type: Categorical, Choices: {polynomial, rbf}, Default: polynomial\n",
      "  Conditions:\n",
      "    coef0 | kernel == 'polynomial'\n",
      "    degree | kernel == 'polynomial'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:65: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:65: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "class KernelRidgeRegression(AutoSklearnRegressionAlgorithm):\n",
    "    def __init__(self, alpha, kernel, gamma, degree, coef0, random_state=None):\n",
    "        self.alpha = alpha\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.random_state = random_state\n",
    "        self.estimator = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.alpha = float(self.alpha)\n",
    "        self.gamma = float(self.gamma)\n",
    "        self.degree = int(self.degree)\n",
    "        self.coef0 = float(self.coef0)\n",
    "\n",
    "        import sklearn.kernel_ridge\n",
    "        self.estimator = sklearn.kernel_ridge.KernelRidge(alpha=self.alpha,\n",
    "                                                          kernel=self.kernel,\n",
    "                                                          gamma=self.gamma,\n",
    "                                                          degree=self.degree,\n",
    "                                                          coef0=self.coef0,\n",
    "                                                          )\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.estimator is None:\n",
    "            raise NotImplementedError\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_properties(dataset_properties=None):\n",
    "        return {'shortname': 'KRR',\n",
    "                'name': 'Kernel Ridge Regression',\n",
    "                'handles_regression': True,\n",
    "                'handles_classification': False,\n",
    "                'handles_multiclass': False,\n",
    "                'handles_multilabel': False,\n",
    "                'handles_multioutput': True,\n",
    "                'is_deterministic': True,\n",
    "                'input': (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n",
    "                'output': (PREDICTIONS,)}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hyperparameter_search_space(dataset_properties=None):\n",
    "        cs = ConfigurationSpace()\n",
    "        alpha = UniformFloatHyperparameter(\n",
    "            name='alpha', lower=10 ** -5, upper=1, log=True, default_value=1.0)\n",
    "        kernel = CategoricalHyperparameter(\n",
    "            name='kernel',\n",
    "            # We restrict ourselves to two possible kernels for this example\n",
    "            choices=['polynomial', 'rbf'],\n",
    "            default_value='polynomial'\n",
    "        )\n",
    "        gamma = UniformFloatHyperparameter(\n",
    "            name='gamma', lower=0.00001, upper=1, default_value=0.1, log=True\n",
    "        )\n",
    "        degree = UniformIntegerHyperparameter(\n",
    "            name='degree', lower=2, upper=5, default_value=3\n",
    "        )\n",
    "        coef0 = UniformFloatHyperparameter(\n",
    "            name='coef0', lower=1e-2, upper=1e2, log=True, default_value=1,\n",
    "        )\n",
    "        cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])\n",
    "        degree_condition = EqualsCondition(degree, kernel, 'polynomial')\n",
    "        coef0_condition = EqualsCondition(coef0, kernel, 'polynomial')\n",
    "        cs.add_conditions([degree_condition, coef0_condition])\n",
    "        return cs\n",
    "\n",
    "\n",
    "# Add KRR component to auto-sklearn.\n",
    "autosklearn.pipeline.components.regression.add_regressor(KernelRidgeRegression)\n",
    "cs = KernelRidgeRegression.get_hyperparameter_search_space()\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1419f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigSpace.configuration_space import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter, \\\n",
    "    UniformIntegerHyperparameter, CategoricalHyperparameter\n",
    "from ConfigSpace.conditions import EqualsCondition\n",
    "\n",
    "import sklearn.metrics\n",
    "import autosklearn.regression\n",
    "import autosklearn.pipeline.components.regression\n",
    "from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\n",
    "from autosklearn.pipeline.constants import SPARSE, DENSE, \\\n",
    "    SIGNED_DATA, UNSIGNED_DATA, PREDICTIONS\n",
    "\n",
    "class ActiveLearningGaussianProcessRegression(AutoSklearnRegressionAlgorithm):\n",
    "    # Based on: https://github.com/automl/auto-sklearn/blob/master/autosklearn/pipeline/components/regression/gaussian_process.py\n",
    "    \n",
    "    def __init__(self, batch_size, n_total, alpha, thetaL, thetaU, random_state=None):\n",
    "       \n",
    "        # Active learner hyperparameters\n",
    "        self.batch_size = batch_size\n",
    "        self.n_total = n_total\n",
    "        \n",
    "        # GPR hyperparameters\n",
    "        self.alpha = alpha\n",
    "        self.thetaL = thetaL\n",
    "        self.thetaU = thetaU\n",
    "        \n",
    "        # Other\n",
    "        self.random_state = random_state\n",
    "        self.estimator = None\n",
    "        self.regressor = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        import sklearn.gaussian_process\n",
    "        import numpy.random\n",
    "        from modAL.models import ActiveLearner\n",
    "        \n",
    "        def GP_regression_std(regressor, X, batch_size):\n",
    "            \"\"\"\n",
    "            Function query based on std predicted by regressor\n",
    "\n",
    "            Args:\n",
    "                regressor (sklearn model): Regression model type to use.\n",
    "                X (np array): Training features\n",
    "                batch_size (int): Number of samples to query.\n",
    "\n",
    "            Returns:\n",
    "                query_idx: indices of chosen samples\n",
    "                X[query_idx]: values of chosen samples\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            _, std = regressor.predict(X, return_std=True)\n",
    "            # Perform argmax for batch_size samples\n",
    "            query_idx = np.argpartition(std, -batch_size)[-batch_size:]\n",
    "\n",
    "            return query_idx, X[query_idx]\n",
    "\n",
    "        self.alpha = float(self.alpha)\n",
    "        self.thetaL = float(self.thetaL)\n",
    "        self.thetaU = float(self.thetaU)\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        kernel = sklearn.gaussian_process.kernels.RBF(\n",
    "            length_scale=[1.0]*n_features,\n",
    "            length_scale_bounds=[(self.thetaL, self.thetaU)]*n_features)\n",
    "\n",
    "        # Instantiate a Gaussian Process model\n",
    "        self.regressor = sklearn.gaussian_process.GaussianProcessRegressor(\n",
    "            kernel=kernel,\n",
    "            n_restarts_optimizer=10,\n",
    "            optimizer='fmin_l_bfgs_b',\n",
    "            alpha=self.alpha,\n",
    "            copy_X_train=True,\n",
    "            random_state=self.random_state,\n",
    "            normalize_y=True,\n",
    "            )\n",
    "\n",
    "        n_batches = int((self.n_total - self.batch_size) / self.batch_size)\n",
    "        n_last_batch = self.n_total - (self.batch_size + n_batches * self.batch_size)\n",
    "\n",
    "        initial_idx = numpy.random.choice(range(len(X)), size=self.batch_size, replace=False)\n",
    "        X_training, y_training = X[initial_idx], y[initial_idx]\n",
    "\n",
    "        self.estimator = ActiveLearner(\n",
    "            estimator=self.regressor,\n",
    "            query_strategy=GP_regression_std, \n",
    "            X_training=X_training, y_training=y_training\n",
    "        )\n",
    "\n",
    "        batches = [self.batch_size for i in range(n_batches)]\n",
    "\n",
    "        if n_last_batch>0:\n",
    "            batches.append(n_last_batch)\n",
    "\n",
    "        for n_queries in batches:\n",
    "            query_idx, query_instance = self.estimator.query(X, self.batch_size)\n",
    "            self.estimator.teach(X[query_idx], y[query_idx])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.estimator is None:\n",
    "            raise NotImplementedError\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_properties(dataset_properties=None):\n",
    "        return {'shortname': 'GPR_AL',\n",
    "                'name': 'ActiveLearningGaussianProcessRegression',\n",
    "                'handles_regression': True,\n",
    "                'handles_classification': False,\n",
    "                'handles_multiclass': False,\n",
    "                'handles_multilabel': False,\n",
    "                'handles_multioutput': False,\n",
    "                'is_deterministic': False,\n",
    "                'input': (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n",
    "                'output': (PREDICTIONS,)}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hyperparameter_search_space(dataset_properties=None):\n",
    "        batch_size = UniformIntegerHyperparameter(\n",
    "            name=\"batch_size\", lower=10, upper=50, default_value=50, log=False)\n",
    "        n_total = UniformIntegerHyperparameter(\n",
    "            name=\"n_total\", lower=100, upper=200, default_value=100, log=False)\n",
    "        alpha = UniformFloatHyperparameter(\n",
    "            name=\"alpha\", lower=1e-14, upper=1.0, default_value=1e-8, log=True)\n",
    "        thetaL = UniformFloatHyperparameter(\n",
    "            name=\"thetaL\", lower=1e-10, upper=1e-3, default_value=1e-6, log=True)\n",
    "        thetaU = UniformFloatHyperparameter(\n",
    "            name=\"thetaU\", lower=1.0, upper=100000, default_value=100000.0, log=True)\n",
    "        \n",
    "        cs = ConfigurationSpace()\n",
    "        cs.add_hyperparameters([batch_size, n_total, alpha, thetaL, thetaU])\n",
    "        return cs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a117b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration space object:\n",
      "  Hyperparameters:\n",
      "    alpha, Type: UniformFloat, Range: [1e-14, 1.0], Default: 1e-08, on log-scale\n",
      "    batch_size, Type: UniformInteger, Range: [10, 50], Default: 50\n",
      "    n_total, Type: UniformInteger, Range: [100, 200], Default: 100\n",
      "    thetaL, Type: UniformFloat, Range: [1e-10, 0.001], Default: 1e-06, on log-scale\n",
      "    thetaU, Type: UniformFloat, Range: [1.0, 100000.0], Default: 100000.0, on log-scale\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:125: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:134: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:134: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# Add GPR_AL component to auto-sklearn.\n",
    "autosklearn.pipeline.components.regression.add_regressor(ActiveLearningGaussianProcessRegression)\n",
    "cs = ActiveLearningGaussianProcessRegression.get_hyperparameter_search_space()\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20b2e786",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoSklearnRegressor(delete_tmp_folder_after_terminate=False, ensemble_nbest=1,\n",
      "                     ensemble_size=1,\n",
      "                     include_estimators=['KernelRidgeRegression'],\n",
      "                     include_preprocessors=['no_preprocessing'],\n",
      "                     initial_configurations_via_metalearning=0,\n",
      "                     memory_limit=6144, n_jobs=2, per_run_time_limit=30,\n",
      "                     resampling_strategy=PredefinedSplit(test_fold=array([10000, 10001, ..., 12100, 12101])),\n",
      "                     time_left_for_this_task=60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:65: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:65: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:125: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:134: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/vneuteboom/anaconda3/envs/master-thesis/lib/python3.7/site-packages/ipykernel_launcher.py:134: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.427677367\n",
      "0.0006747310000037032\n",
      "-1.1378076504560326\n",
      "[(1.000000, MyDummyRegressor(config=1,\n",
      "                 init_params={'data_preprocessing:feat_type': {0: 'numerical',\n",
      "                                                               1: 'numerical',\n",
      "                                                               2: 'numerical',\n",
      "                                                               3: 'numerical',\n",
      "                                                               4: 'numerical',\n",
      "                                                               5: 'numerical',\n",
      "                                                               6: 'numerical',\n",
      "                                                               7: 'numerical',\n",
      "                                                               8: 'numerical',\n",
      "                                                               9: 'numerical',\n",
      "                                                               10: 'numerical',\n",
      "                                                               11: 'numerical',\n",
      "                                                               12: 'numerical',\n",
      "                                                               13: 'numerical',\n",
      "                                                               14: 'numerical'},\n",
      "                              'instance': None},\n",
      "                 random_state=1)),\n",
      "]\n",
      "auto-sklearn results:\n",
      "  Dataset name: b4990298-05d2-11ec-ba28-9cb6d0bfebdf\n",
      "  Metric: r2\n",
      "  Number of target algorithm runs: 100\n",
      "  Number of successful target algorithm runs: 0\n",
      "  Number of crashed target algorithm runs: 100\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    autosklearn.pipeline.components.regression.add_regressor(KernelRidgeRegression)\n",
    "\n",
    "    model = {\n",
    "                \"model_type\":AutoSklearnRegressor,\n",
    "                \"hyperparams\":\n",
    "                {\n",
    "                    \"time_left_for_this_task\": 1*60,\n",
    "                    \"per_run_time_limit\":1*30,\n",
    "                    \"initial_configurations_via_metalearning\":0,\n",
    "                    \"ensemble_size\":1,\n",
    "                    \"ensemble_nbest\":1,\n",
    "#                     \"output_folder\":\"/tmp/autosklearn_output\",\n",
    "                    \"n_jobs\":2,\n",
    "                    \"delete_tmp_folder_after_terminate\":False,\n",
    "#                     \"delete_output_folder_after_terminate\":True,\n",
    "                    \"include_preprocessors\":[\"no_preprocessing\"], \n",
    "                    \"exclude_preprocessors\":None,\n",
    "                    \"memory_limit\":1024*6,\n",
    "                    \"include_estimators\":[\"KernelRidgeRegression\"]\n",
    "                }\n",
    "           }\n",
    "\n",
    "    target_cols=(\"lai\", \"LAI_Warren\")\n",
    "    feature_cols=['B1', 'B2', 'B3', 'B4', 'B5', 'B6', \\\n",
    "                  'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \\\n",
    "                  'solar_zenith', 'observer_zenith', 'relative_azimuth']\n",
    "    standardize=False\n",
    "\n",
    "\n",
    "    model[\"hyperparams\"][\"resampling_strategy\"] = PredefinedSplit(test_fold=range(len(train_df), len(train_df)+len(validation_df)))\n",
    "\n",
    "    all_cols = feature_cols.copy()\n",
    "    all_cols.append(target_cols[1])\n",
    "\n",
    "    train_data = (train_df[all_cols].append(validation_df[all_cols])).reindex()\n",
    "    test_data = test_df\n",
    "\n",
    "    # Train on entire training set\n",
    "    X_train = np.array(train_data[feature_cols])\n",
    "    y_train = np.array(train_data[target_cols[1]]) \n",
    "\n",
    "    # Shuffle training set\n",
    "    # idx = np.arange(len(X_train))\n",
    "    # np.random.shuffle(idx)\n",
    "\n",
    "    # X_train = X_train[idx]\n",
    "    # y_train = y_train[idx]\n",
    "\n",
    "    X_test = np.array(test_data[feature_cols])\n",
    "    y_test = np.array(test_data[target_cols[1]]) \n",
    "\n",
    "    # Standardize data\n",
    "    if standardize:\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit model on entire training set\n",
    "    t_start = time.process_time()\n",
    "\n",
    "    # Random Forest\n",
    "    # model = {\n",
    "    #     \"model_type\":RandomForestRegressor,\n",
    "    #     \"hyperparams\":\n",
    "    #     {\n",
    "    #         \"n_estimators\": 100,\n",
    "    #     }\n",
    "    # }\n",
    "\n",
    "\n",
    "    model = model[\"model_type\"](**model[\"hyperparams\"])\n",
    "\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    model.refit(X_train[:len(train_df)], y_train[:len(train_df)])\n",
    "    # Get training set predictions  \n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    train_time = time.process_time()-t_start\n",
    "\n",
    "    # Get test set predictions\n",
    "    t_start = time.process_time()\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_time = time.process_time()-t_start\n",
    "\n",
    "    print(train_time)\n",
    "    print(test_time)\n",
    "    print(r2_score(y_test, y_test_pred))\n",
    "\n",
    "    m = model.show_models()\n",
    "    print(model.show_models())\n",
    "    print(model.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5832d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = UniformIntegerHyperparameter(\n",
    "    name=\"batch_size\", lower=10, upper=1500, default_value=50, log=False)\n",
    "n_total = UniformIntegerHyperparameter(\n",
    "    name=\"n_total\", lower=100, upper=2000, default_value=1000, log=False)\n",
    "alpha = UniformFloatHyperparameter(\n",
    "    name=\"alpha\", lower=1e-14, upper=1.0, default_value=1e-8, log=True)\n",
    "thetaL = UniformFloatHyperparameter(\n",
    "    name=\"thetaL\", lower=1e-10, upper=1e-3, default_value=1e-6, log=True)\n",
    "thetaU = UniformFloatHyperparameter(\n",
    "    name=\"thetaU\", lower=1.0, upper=100000, default_value=100000.0, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b521266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = ActiveLearningGaussianProcessRegression(50, 100, 1e-8, 1e-6, 1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07379da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a192c284c96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-17e49b0dd248>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mnormalize_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             n_jobs=1)\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_total\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_jobs'"
     ]
    }
   ],
   "source": [
    "test_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8157efe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.20827761e-01,  3.16907660e+00,  5.13982876e+00,  2.15780698e-01,\n",
       "        3.28044838e+00,  2.73789752e+00,  3.28935383e+00,  1.97566259e+00,\n",
       "        5.22953081e+00,  3.42393846e+00,  3.83016927e-04,  6.63560142e-01,\n",
       "        2.67265062e+00,  9.16715284e-03,  2.88939263e+00,  2.29336090e+00,\n",
       "        3.05721848e-01,  6.79985903e-01,  7.08492998e-01,  3.34438007e-03,\n",
       "        3.93058329e-01,  4.60579470e+00,  3.76020487e+00,  1.76321251e+00,\n",
       "        6.74150757e+00,  3.46966863e+00,  1.14194947e+00,  6.00843213e+00,\n",
       "        4.09594838e+00,  2.79667327e-01,  3.34351506e+00,  2.33012349e+00,\n",
       "        4.43214816e+00,  8.69891495e-02,  6.16600645e+00,  2.25519534e+00,\n",
       "        5.33288852e+00,  7.66871765e+00,  8.64010465e-03,  2.40095003e+00,\n",
       "        4.71498236e+00,  4.06579015e+00,  2.86628893e+00,  3.03448944e+00,\n",
       "        3.84430575e+00,  4.86061788e+00,  3.46786307e+00,  2.66764154e+00,\n",
       "        6.27848706e-01,  9.25075713e-01,  1.81216524e+00,  6.00377367e+00,\n",
       "        4.15957710e+00, -1.00749597e-02,  4.23004470e+00,  8.10821302e-01,\n",
       "        5.34337146e+00,  6.02355130e+00,  2.59891027e+00,  3.22184584e+00,\n",
       "        2.33328137e+00,  1.59651573e+00,  2.96790478e-01,  3.07413341e+00,\n",
       "        5.89174183e+00,  3.28207606e+00,  3.13005898e+00,  3.60057492e+00,\n",
       "        5.74865113e-02,  5.45316637e+00,  2.40332341e-02,  3.83873147e+00,\n",
       "        3.81893128e+00,  9.63432082e-01,  1.45890121e+00,  2.92767940e+00,\n",
       "        8.31930411e-01,  5.54864974e+00,  3.98260576e+00,  3.98207464e+00,\n",
       "        2.31378275e+00,  3.21419535e+00,  2.33358962e+00,  4.37520278e+00,\n",
       "        1.54474590e+00,  2.10541983e+00, -2.71074062e-03,  1.28915081e+00,\n",
       "        3.62844368e+00,  1.89049284e+00,  5.20969906e+00,  3.99040052e+00,\n",
       "        3.84200095e-02,  6.50556245e-01,  6.33797529e+00,  3.67138288e+00,\n",
       "        3.94635338e+00,  1.64316938e-01,  3.66796304e+00,  4.01455539e+00,\n",
       "        4.17571395e+00,  1.64149299e+00,  4.03346234e+00,  5.33671255e+00,\n",
       "        4.28818389e+00,  4.95620408e+00,  5.00178657e+00,  4.91089036e+00,\n",
       "        3.71965991e+00,  5.96815236e+00,  2.69469815e+00, -1.58534212e-01,\n",
       "        3.93453709e-01,  3.11960960e+00,  3.60139180e+00,  5.07717204e+00,\n",
       "        2.25360189e+00,  2.69461177e+00,  1.83239068e+00,  4.48360313e+00,\n",
       "        2.43937050e+00,  6.67901449e-01,  3.25163380e+00,  5.74493748e+00,\n",
       "        1.58523179e+00,  1.44974265e-01, -3.48075014e-02,  1.99257873e+00,\n",
       "        5.02610255e+00,  1.29823594e-01,  4.08105590e+00,  1.36574359e+00,\n",
       "        2.62544057e+00,  2.16176860e+00,  5.24399117e+00,  1.42392096e+00,\n",
       "        4.16091985e+00,  1.60752982e+00,  5.02085435e-01,  3.75823059e+00,\n",
       "        6.02326860e+00,  2.80037337e+00,  1.74014989e-01,  1.96881854e+00,\n",
       "        3.13985492e+00,  8.29784002e-01,  3.34218089e+00,  5.29473195e+00,\n",
       "        5.17112410e+00,  4.41402273e+00,  6.05356963e+00,  4.50172165e+00,\n",
       "        5.78251990e+00,  3.20060043e+00,  4.11456736e+00,  7.73438179e+00,\n",
       "        3.84386289e+00,  1.30079567e+00,  3.37626064e+00,  2.63501942e+00,\n",
       "        3.80487713e+00,  4.44820722e+00,  3.94983146e+00,  1.79621498e-01,\n",
       "        4.33589575e+00,  6.45992075e-01,  2.26421047e+00,  5.60019313e+00,\n",
       "        3.16178520e+00,  1.54289570e+00,  1.32147681e+00, -5.42904944e-02,\n",
       "        2.96413613e+00,  3.70506907e+00,  4.16660531e+00,  6.06306079e-01,\n",
       "        1.31249602e-01,  2.57012001e+00,  3.26519908e+00,  3.82222119e+00,\n",
       "        2.39134745e+00,  4.38491964e+00,  4.94706262e+00,  1.66627384e-01,\n",
       "        6.70334809e+00,  4.39986416e+00,  1.43193322e+00,  3.71766922e+00,\n",
       "       -4.71384406e-02,  2.57989009e+00,  3.89880567e+00,  3.24431962e+00,\n",
       "        8.28896096e-03,  5.38059695e-01,  4.43930420e+00,  3.58292958e+00,\n",
       "        3.20060043e+00,  1.33669815e+00,  5.15288587e+00,  1.30798315e+00,\n",
       "        4.86476805e+00,  4.28197690e+00,  6.55994327e+00,  5.55352335e+00,\n",
       "        3.00919596e+00,  2.89634531e+00,  3.91193851e+00,  2.12385483e+00,\n",
       "        4.10066773e+00,  1.01332030e+00,  3.01769079e+00,  3.09260811e+00,\n",
       "        4.27825419e+00,  3.72995668e+00,  2.74185219e+00,  4.77400219e+00,\n",
       "        5.52980419e-01,  3.91772956e+00,  1.08076527e-01,  1.44974265e-01,\n",
       "        2.57640896e+00,  1.94156026e+00,  4.57094292e-01,  6.41627697e+00,\n",
       "        6.43909365e-01,  8.79722883e-01,  4.48208561e+00,  3.80036598e+00,\n",
       "        3.03118325e+00,  5.51921521e-01,  2.36936029e+00,  3.47332583e+00,\n",
       "        4.96568305e+00,  2.55604027e+00,  3.92910750e+00,  3.54451758e+00,\n",
       "        4.74828650e+00, -4.97524298e-01,  3.66988844e+00,  8.74839626e-01,\n",
       "        5.59888114e+00,  2.60518210e-02,  4.61937937e+00,  6.25517198e+00,\n",
       "        3.76203182e+00,  4.27280210e+00,  3.10295141e-01,  1.73739257e+00,\n",
       "        3.09256140e+00,  3.17023195e+00,  1.74021452e+00,  3.05280580e+00,\n",
       "       -6.16690816e-02,  3.32347650e+00,  7.38561306e+00,  4.69668009e+00,\n",
       "        6.03860496e+00,  7.18348396e+00,  4.11347453e+00,  1.14239555e+00,\n",
       "        4.36206327e-01,  8.78271803e-01,  4.34408401e+00,  9.44894287e-01,\n",
       "        1.54562586e+00,  1.12829025e+00,  1.04544288e-02,  8.13912504e-01,\n",
       "        3.42866211e+00,  2.37370981e+00,  2.52383974e-01,  7.83542864e-01,\n",
       "        5.15045498e-02,  3.50070755e-02,  3.51003550e+00,  2.59108323e+00,\n",
       "       -1.72664396e-03,  5.24330927e+00,  8.59409318e-01,  2.58469078e+00,\n",
       "        3.04848222e+00, -8.91872264e-02,  5.34372770e+00,  6.59199876e+00,\n",
       "        1.32219413e-01,  6.35007648e+00,  3.36928961e+00,  3.36460990e-01,\n",
       "        1.85004144e-01,  5.82674379e+00,  2.63826729e+00,  6.65381990e+00,\n",
       "        1.04209796e+00,  7.07312485e+00,  4.19732645e+00,  3.80192513e+00,\n",
       "        1.34800397e+00,  3.69949798e+00,  3.60734640e+00,  2.85865727e+00,\n",
       "        5.28383139e+00,  2.82283685e+00,  4.67849893e+00,  4.23518948e+00,\n",
       "        3.76200717e+00,  5.52509646e-01,  1.77170935e+00,  1.09781216e+00,\n",
       "        2.87610109e+00,  2.30385211e+00,  2.66223675e-02,  9.75901058e-01,\n",
       "        1.07682948e+00,  4.63932502e+00,  5.17591094e+00,  3.93710846e+00,\n",
       "        4.51077807e+00,  1.84241340e+00,  4.98280513e+00,  1.05590575e+00,\n",
       "        2.23725251e+00,  4.47772859e+00,  3.38664861e+00,  2.62041548e+00,\n",
       "        5.35237435e+00,  4.22592449e+00,  2.24150262e+00,  4.11254273e+00,\n",
       "        6.38266505e+00,  5.76409771e+00,  8.76067802e-02,  8.45323951e-01,\n",
       "        3.89548923e+00,  3.17023195e+00,  2.18961341e+00,  4.26227391e+00,\n",
       "        1.98198427e+00,  1.23604856e+00,  2.81878366e+00,  4.85651128e+00,\n",
       "        2.23761401e+00,  2.94648172e+00,  7.48180445e-01,  2.16843318e+00,\n",
       "       -2.93722941e-02,  3.79457673e+00,  2.01760884e+00,  7.17690864e-01,\n",
       "        2.27974247e+00,  3.71441817e+00,  1.38152895e+00,  1.12609636e+00,\n",
       "        3.30442924e+00,  4.37854669e+00,  4.07777513e+00,  4.20106708e+00,\n",
       "        3.55190758e+00,  1.80180275e+00,  9.88975904e-01,  2.99647396e+00,\n",
       "        3.65076817e+00,  1.88591993e+00,  3.12716527e+00,  7.80261820e-02,\n",
       "        7.21379088e-01,  1.63193060e+00,  3.44810358e+00,  2.25893264e+00,\n",
       "        3.50375910e+00,  5.77192444e-01,  2.94800950e+00,  2.96349158e+00,\n",
       "        2.83287983e+00,  1.18990065e+00,  2.83229304e+00,  1.79508824e+00,\n",
       "        7.19432020e+00,  5.79392170e+00, -9.88677212e-01,  6.77720518e-01,\n",
       "        2.46997588e+00,  8.34441916e-01, -1.87811312e-02,  3.23155024e+00,\n",
       "        3.67421937e+00,  2.67710919e+00,  5.56523293e+00,  2.87784330e+00,\n",
       "        2.33320362e+00, -2.26340867e-03, -1.23330838e-01,  1.56083816e+00,\n",
       "        9.90531438e-01,  9.28647994e-01,  1.01191089e+00,  3.04748732e+00,\n",
       "        2.86992644e+00,  3.18549862e+00,  6.43471599e+00,  5.50617082e+00,\n",
       "        1.59729721e+00,  1.26936101e+00,  5.79959844e-01,  5.22953081e+00,\n",
       "        3.90764429e+00,  2.14230573e-02,  2.69367569e+00,  5.17341942e+00,\n",
       "        3.08142457e+00, -9.51225720e-02,  4.61379248e+00,  3.03983291e+00,\n",
       "        4.19963755e+00,  7.79875660e-02,  4.00047559e+00,  1.62810187e+00,\n",
       "        7.19086482e+00,  6.07780570e+00,  1.46917805e+00,  4.16793803e+00,\n",
       "        4.13472627e+00,  1.89725087e-01,  9.91812750e-02,  3.89548923e+00,\n",
       "        4.26506031e+00,  1.01674804e-02,  2.50741111e+00,  4.26734548e+00,\n",
       "        5.81643529e+00,  3.91087242e+00,  2.57881081e+00,  2.94685258e+00,\n",
       "        2.72429254e+00,  3.24790854e+00,  2.29782595e+00,  5.56836380e+00,\n",
       "        3.89761592e+00,  2.31386344e+00,  7.32384008e-02,  4.01455539e+00,\n",
       "        1.59329643e+00,  3.27159348e+00,  2.26919008e+00,  2.08008740e+00,\n",
       "        1.32374280e-01,  4.76915153e-01,  5.26307853e+00,  2.98075843e+00,\n",
       "        1.16947807e-02,  3.48348011e+00,  2.24018777e+00,  6.00450472e+00,\n",
       "        1.66850740e+00,  9.19242987e-01,  2.08731961e+00,  4.08388365e+00,\n",
       "        4.68168441e+00,  2.97473961e+00,  5.11161499e+00,  2.95454672e+00,\n",
       "        9.52330168e-02,  3.52510167e+00,  4.03886374e+00,  2.40748185e+00,\n",
       "        3.88516880e+00,  3.48135847e+00,  2.08843187e+00,  1.08667179e+00,\n",
       "       -2.85644839e-02,  8.06051039e-02,  8.27920665e-02,  4.05195504e+00,\n",
       "        2.77911687e+00,  7.13678837e-01,  1.14194947e+00,  8.20900149e-01,\n",
       "        3.42469623e+00,  3.36280314e+00,  4.31283992e+00,  4.11878656e+00,\n",
       "        3.64096670e+00,  2.25049716e+00,  3.90945264e+00,  4.04198391e+00,\n",
       "        2.98512322e+00,  7.00650845e-02,  3.07123269e+00,  3.28413979e+00,\n",
       "        7.19086482e+00,  1.69325900e+00,  2.45739453e+00, -1.36869339e-02,\n",
       "        1.96499431e+00,  2.46233828e+00,  6.50743963e-01,  1.33013668e+00,\n",
       "        5.71555981e+00,  3.65398282e+00,  3.34025204e+00,  1.62654195e+00,\n",
       "       -7.61698933e-02,  2.28052724e+00,  2.63433675e-02,  3.69453392e+00,\n",
       "        5.35219946e-02,  6.52365426e+00,  4.78798992e+00,  5.62636254e-01,\n",
       "        5.09720801e-03,  2.82357489e+00,  9.46967450e-01,  9.90725229e-01,\n",
       "        2.76598909e+00, -3.34130027e-01,  3.96301361e+00,  1.38101417e+00,\n",
       "        1.65822331e-01,  5.25857893e-01,  1.08031115e+00,  1.07224854e+00,\n",
       "        2.71792772e+00,  3.67818614e-01,  4.26713639e-02,  3.44675543e-01,\n",
       "        3.82738235e+00,  3.44591183e+00,  1.99030662e-01, -3.98035060e-02,\n",
       "        9.82303787e-01,  4.57094292e-01,  3.60765009e+00,  2.12732859e+00,\n",
       "        3.22440811e+00,  6.92475384e+00,  1.24285725e-01,  4.47207068e+00,\n",
       "        4.07503619e+00,  3.04039175e+00,  5.77365063e-01,  1.61904317e+00,\n",
       "        2.96105464e-01,  3.09741564e+00,  1.66692776e-03,  1.31249602e-01,\n",
       "        2.95104772e+00,  2.89761508e+00,  4.70722847e-03,  4.88379607e+00,\n",
       "        3.90129110e+00,  3.86854337e+00,  1.84686079e+00,  9.35983505e-01,\n",
       "        4.95758016e+00,  3.77649558e+00,  1.23810348e-01,  1.93063212e+00,\n",
       "        6.03208965e+00,  3.86481999e+00,  3.95241885e+00,  4.52809447e+00,\n",
       "        3.22293676e+00, -2.98605734e-02,  5.03828901e+00,  1.35921611e+00,\n",
       "        4.74607139e+00,  2.91046366e+00,  6.30835916e+00,  3.23577094e+00,\n",
       "        2.43021050e+00,  1.44334037e+00,  3.00919596e+00,  4.62336179e+00,\n",
       "        4.41143234e+00,  4.15476612e+00,  3.62972972e+00,  2.08300525e+00,\n",
       "       -3.73200551e-02,  5.38844842e+00,  3.46966863e+00,  1.37466107e+00,\n",
       "       -2.66599587e-01, -1.84028542e-03,  8.86819039e-01,  4.69733761e+00,\n",
       "        4.68840779e+00,  4.13006466e+00,  1.22060207e+00,  2.18058471e-02,\n",
       "        5.11667239e+00,  3.28598576e-01,  1.64670048e+00,  7.62445851e-02,\n",
       "        2.93834533e+00,  3.57458890e+00,  2.91247396e+00,  7.80124740e-01,\n",
       "        2.81608594e-02,  1.35289361e+00,  3.27242982e+00,  5.60713509e+00,\n",
       "        3.58733980e+00,  2.57708481e+00,  3.76770592e+00,  2.94349059e+00,\n",
       "        1.64537371e+00,  3.22717107e+00,  3.39545953e+00,  2.65948244e+00,\n",
       "        2.04022279e+00,  9.12107305e-01,  1.36615490e-01,  5.56438103e+00,\n",
       "        4.12415157e+00,  3.28042397e+00,  3.69256891e+00,  3.74869846e+00,\n",
       "        3.54239114e+00,  4.07770042e+00,  7.36892516e+00,  4.50100906e+00,\n",
       "        3.53530596e+00,  2.63360836e-01,  3.03594631e+00,  3.24030112e-02,\n",
       "        5.17693796e+00,  5.01357799e+00,  6.46085834e-01,  3.66255465e+00,\n",
       "        2.44918129e+00,  5.09049565e+00,  4.07735100e+00,  3.21045677e+00,\n",
       "        1.28583380e+00,  5.38744946e+00,  4.80328247e+00,  1.14556119e+00,\n",
       "        6.71701167e+00,  2.82483339e+00,  9.86716987e-01,  4.13554455e+00,\n",
       "        4.39441071e+00,  1.26852353e+00,  6.57102953e-02,  4.57223474e+00,\n",
       "        3.11577771e+00,  4.56039251e+00,  1.07390546e+00,  3.88516880e+00,\n",
       "        3.00042677e+00,  1.01198211e+00,  1.49171838e+00,  4.37050760e+00,\n",
       "        3.22392101e+00,  7.86045938e+00,  3.21040248e+00,  4.21620351e+00,\n",
       "        4.65296535e+00,  1.04765298e-01,  1.70311753e+00,  1.59329643e+00,\n",
       "        3.05819124e+00,  3.29513342e+00,  3.33829771e+00,  6.66524473e+00,\n",
       "        3.29526236e+00,  9.45618775e-01,  4.89543939e+00,  9.16715284e-03,\n",
       "        4.52985114e+00,  1.57587741e+00,  9.96136597e-01,  2.39913526e+00,\n",
       "        1.14215880e+00,  3.83873147e+00,  2.45046571e+00,  1.93178371e+00,\n",
       "        2.56130428e+00,  2.82377752e+00,  1.03390172e+00,  5.48950428e+00,\n",
       "        4.41705918e-02,  3.07557220e-01,  2.86803477e+00,  3.69949798e+00,\n",
       "        2.58314015e+00,  4.12562315e+00,  7.31622016e-01,  4.34052312e+00,\n",
       "       -2.08704612e-02,  1.35269459e-01,  5.84914929e+00,  2.43853376e+00,\n",
       "        1.53500329e+00,  4.37135796e+00,  3.69225880e+00,  1.28249032e+00,\n",
       "        3.44328601e+00,  9.81469516e-01,  3.09691642e+00,  3.84246223e+00,\n",
       "        5.09319685e+00,  4.37877438e+00,  3.59555455e+00,  4.14735134e-01,\n",
       "        4.91299680e+00,  2.42017457e+00,  2.26197096e+00,  2.37249314e+00,\n",
       "        3.77233712e+00,  6.45015459e+00,  2.76215197e+00,  3.68000718e+00,\n",
       "        3.18432141e+00,  5.10850680e+00,  1.44295743e-02,  4.47207068e+00,\n",
       "        1.83226118e-02,  7.97548160e-01,  4.19709858e+00,  2.56183011e+00,\n",
       "        2.71406739e+00,  1.52179529e+00,  8.08176519e-03,  6.19626447e+00,\n",
       "        3.85968494e+00,  1.30432275e+00,  3.55729951e+00,  2.40279216e+00,\n",
       "        4.26271483e+00,  4.08105590e+00,  2.21518819e-01, -1.06744831e-01,\n",
       "        3.47910763e+00,  5.01784280e-01,  4.57541914e+00,  2.42162492e+00,\n",
       "        1.84241340e+00,  4.64000661e+00,  9.62549825e-01,  8.48198813e-01,\n",
       "        5.41248344e-01,  3.04971177e+00,  4.74162608e+00,  6.45992075e-01,\n",
       "        3.46525195e+00,  3.44024218e+00,  3.14169734e+00,  3.45921822e+00,\n",
       "        2.79867266e+00,  4.45243934e+00,  2.71910023e+00,  1.76402630e+00,\n",
       "        3.76063598e+00,  3.32192816e+00,  1.03274083e+00,  3.13183255e+00,\n",
       "        3.90858659e+00,  3.12393214e+00,  2.29735011e+00,  3.68816368e-02,\n",
       "       -1.18365761e-02,  5.73110673e+00,  3.02053975e+00,  4.16092137e+00,\n",
       "        2.12140247e+00,  4.01974243e+00,  3.68113887e+00,  4.71427284e+00,\n",
       "        2.15898159e+00,  2.21939705e+00,  2.24987973e+00,  4.54069158e+00,\n",
       "        1.30017277e+00,  3.56444888e+00,  4.16247238e+00,  1.67318777e+00,\n",
       "        2.48513969e+00,  6.06297582e+00,  3.48679227e+00,  7.18995340e+00,\n",
       "        4.68353784e-02,  4.45132371e+00,  7.61389830e-03,  1.67607371e-01,\n",
       "        3.25401914e+00,  2.46456920e+00,  1.69378063e+00,  3.61813432e+00,\n",
       "        3.48409893e+00,  7.26034622e-02,  3.76544031e+00,  2.60072445e+00,\n",
       "        2.84318936e-01,  4.57039606e+00,  5.50651194e+00,  9.21140855e-01,\n",
       "        1.89039711e+00,  4.54395836e+00,  4.08949365e+00,  4.93305020e+00,\n",
       "        1.83293066e+00,  2.09365334e+00,  3.10477232e+00,  3.04484758e+00,\n",
       "        2.62466541e-01,  4.53066980e+00,  3.96019252e+00,  2.21401849e+00,\n",
       "        3.14562862e+00,  2.86684401e+00,  3.92429347e+00,  6.60268273e+00,\n",
       "        1.82606932e-02,  1.33013668e+00,  4.01205755e+00,  3.49557933e+00,\n",
       "        2.85383429e+00,  3.93019344e+00,  2.08858192e+00,  2.41646082e+00,\n",
       "        3.64926405e+00,  2.00487134e-02,  3.45754960e-02,  4.95908707e+00,\n",
       "        7.44744298e-01,  2.89357476e+00,  2.91000423e+00,  4.89475783e+00,\n",
       "        6.46197192e+00,  6.75989665e+00,  4.60357506e+00,  2.74588533e+00,\n",
       "        5.03520784e+00,  2.28895145e+00,  3.76359857e+00,  1.86174376e+00,\n",
       "       -1.10111816e-01,  9.70934343e-01,  1.62533573e+00,  4.83505503e+00,\n",
       "        3.29648280e+00,  1.93111162e+00,  2.73173575e+00,  1.33939012e+00,\n",
       "        3.94393817e+00,  4.08949365e+00,  7.20709404e-01,  4.33513374e+00,\n",
       "        2.42466006e+00,  3.71881951e+00, -8.17348272e-03,  2.20896547e+00,\n",
       "        3.86670850e+00, -1.09191630e-02,  3.60688853e+00,  3.11085375e+00,\n",
       "        2.16705064e+00,  5.11161499e+00,  1.68557506e-01,  2.21939705e+00,\n",
       "        6.28194078e+00,  8.98388060e-01,  2.52030582e+00,  1.13095880e+00,\n",
       "        3.47457418e+00,  8.00649161e-01,  3.80036598e+00,  6.66996995e+00,\n",
       "        3.73604832e+00,  4.69668009e+00,  1.49776149e+00,  2.78176616e+00,\n",
       "        7.44106401e+00,  3.72599604e-01,  6.38344933e+00,  5.15965207e+00,\n",
       "        3.03034548e+00,  2.20934861e+00,  1.71796248e+00,  7.71051054e-02,\n",
       "        3.77649558e+00,  3.30884507e+00,  4.27641613e+00,  4.53752589e+00,\n",
       "        4.79944947e-03,  3.92064804e-01,  1.89656287e-01,  7.18995340e+00,\n",
       "        2.95595689e+00,  3.90835275e+00,  6.69328957e+00,  3.05738846e+00,\n",
       "        1.27342692e+00,  1.36615490e-01,  2.34627332e+00,  3.07374928e+00,\n",
       "        4.20631543e+00,  7.36756989e-01,  2.87032026e+00,  3.59072303e+00,\n",
       "        4.80921672e+00,  5.07974146e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f64e80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4., ..., 4., 4., 4.], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_models_with_weights()[0][1].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stacked_ensemble(X_train, y_train, automl):\n",
    "    X_temp = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5632f2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1.000000, MyDummyRegressor(config=1, init_params={'instance': None}, random_state=1)),\\n]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd0bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoSklearnRegressor(ensemble_nbest=1, ensemble_size=1,\n",
      "                     include_preprocessors=['no_preprocessing'],\n",
      "                     initial_configurations_via_metalearning=0, n_jobs=2,\n",
      "                     output_folder='/tmp/autosklearn_output',\n",
      "                     per_run_time_limit=60,\n",
      "                     resampling_strategy=<class 'sklearn.model_selection._split.PredefinedSplit'>,\n",
      "                     resampling_strategy_arguments={'test_fold': range(10000, 12102)},\n",
      "                     time_left_for_this_task=300,\n",
      "                     tmp_folder='/tmp/autosklearn_tmp')\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d9fda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2809341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator \n",
    "from sklearn.base import RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb77e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoMLStackingRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, automl, final_estimator, **model_hyper_parameters):\n",
    "        \"\"\"\n",
    "        Works similar to sklearn's StackingRegressor, \n",
    "        except that the input estimators are not refitted during a call to fit().\n",
    "\n",
    "        param automl: Fitted auto-sklearn object, from which estimator pipelines can be extracted\n",
    "        param final_estimator: Untrained sklearn estimator\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.automl = automl\n",
    "        self.final_estimator = final_estimator\n",
    "        self.is_fit=False\n",
    "    \n",
    "    def _get_estimators(self):\n",
    "        \"\"\"\n",
    "        Extracts estimators from autosklearn object\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.estimators = [m[1] for m in self.automl.get_models_with_weights()]\n",
    "        return\n",
    "    \n",
    "    def _get_X_final_model(self, X):\n",
    "        \"\"\"\n",
    "        Adds predictions from autosklearn estimators as features in X\n",
    "        \"\"\"\n",
    "    \n",
    "        y_pred = np.array([estimator.predict(X) for estimator in self.estimators]).reshape(-1,1)\n",
    "        X_final_model = np.c_[X, y_pred]  \n",
    "        return X_final_model\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._get_estimators()\n",
    "        \n",
    "        X_final_model = self._get_X_final_model(X)\n",
    "\n",
    "        self.final_estimator.fit(X_final_model, y)\n",
    "        self._fit=True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert(self._fit==True), \"Unable to predict. Call the fit() function first!\"\n",
    "\n",
    "        X_final_model = self._get_X_final_model(X)\n",
    "\n",
    "        y_pred = self.final_estimator.predict(X_final_model)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8095be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = AutoMLStackingRegressor(automl=model, final_estimator=RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e27475fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLStackingRegressor(automl=AutoSklearnRegressor(ensemble_nbest=1,\n",
       "                                                    ensemble_size=1,\n",
       "                                                    include_preprocessors=['no_preprocessing'],\n",
       "                                                    initial_configurations_via_metalearning=0,\n",
       "                                                    n_jobs=2,\n",
       "                                                    output_folder='/tmp/autosklearn_output',\n",
       "                                                    per_run_time_limit=60,\n",
       "                                                    resampling_strategy=<class 'sklearn.model_selection._split.PredefinedSplit'>,\n",
       "                                                    resampling_strategy_arguments={'test_fold': range(10000, 12102)},\n",
       "                                                    time_left_for_this_task=300,\n",
       "                                                    tmp_folder='/tmp/autosklearn_tmp'),\n",
       "                        final_estimator=RandomForestRegressor())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train[len(train_df):], y_train[len(train_df):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fab152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8639054640853376"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdcc5395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n</th>\n",
       "      <th>cab</th>\n",
       "      <th>car</th>\n",
       "      <th>cbrown</th>\n",
       "      <th>cw</th>\n",
       "      <th>cm</th>\n",
       "      <th>LAI_Warren</th>\n",
       "      <th>lidfa</th>\n",
       "      <th>hspot</th>\n",
       "      <th>...</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.129195</td>\n",
       "      <td>0.154254</td>\n",
       "      <td>0.167312</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.082803</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>0.042489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>17.321374</td>\n",
       "      <td>4.330344</td>\n",
       "      <td>0.577379</td>\n",
       "      <td>0.057738</td>\n",
       "      <td>0.057738</td>\n",
       "      <td>2.309517</td>\n",
       "      <td>23.095165</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>0.040281</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>0.082582</td>\n",
       "      <td>0.091378</td>\n",
       "      <td>0.096391</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.068753</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>0.062521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000075</td>\n",
       "      <td>20.003000</td>\n",
       "      <td>1.000750</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5.004000</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.017731</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2499.75000</td>\n",
       "      <td>1.375037</td>\n",
       "      <td>35.001500</td>\n",
       "      <td>4.750375</td>\n",
       "      <td>0.500050</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>2.000200</td>\n",
       "      <td>25.002000</td>\n",
       "      <td>0.062501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>0.100939</td>\n",
       "      <td>0.104070</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>0.035046</td>\n",
       "      <td>0.023089</td>\n",
       "      <td>0.009617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022311</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>0.118740</td>\n",
       "      <td>0.139087</td>\n",
       "      <td>0.149228</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.153295</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.013295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7499.25000</td>\n",
       "      <td>2.124963</td>\n",
       "      <td>64.998500</td>\n",
       "      <td>12.249625</td>\n",
       "      <td>1.499950</td>\n",
       "      <td>0.149995</td>\n",
       "      <td>0.149995</td>\n",
       "      <td>5.999800</td>\n",
       "      <td>64.998000</td>\n",
       "      <td>0.087499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>0.083503</td>\n",
       "      <td>0.167918</td>\n",
       "      <td>0.198793</td>\n",
       "      <td>0.215923</td>\n",
       "      <td>0.224203</td>\n",
       "      <td>0.224990</td>\n",
       "      <td>0.105039</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.041685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>2.499925</td>\n",
       "      <td>79.997000</td>\n",
       "      <td>15.999250</td>\n",
       "      <td>1.999900</td>\n",
       "      <td>0.199990</td>\n",
       "      <td>0.199990</td>\n",
       "      <td>7.999600</td>\n",
       "      <td>84.996000</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200144</td>\n",
       "      <td>0.220337</td>\n",
       "      <td>0.598948</td>\n",
       "      <td>0.793209</td>\n",
       "      <td>0.779937</td>\n",
       "      <td>0.765597</td>\n",
       "      <td>0.778564</td>\n",
       "      <td>0.725032</td>\n",
       "      <td>0.701275</td>\n",
       "      <td>0.530866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             n           cab           car        cbrown  \\\n",
       "count  10000.00000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean    4999.50000      1.750000     50.000000      8.500000      1.000000   \n",
       "std     2886.89568      0.433034     17.321374      4.330344      0.577379   \n",
       "min        0.00000      1.000075     20.003000      1.000750      0.000100   \n",
       "25%     2499.75000      1.375037     35.001500      4.750375      0.500050   \n",
       "50%     4999.50000      1.750000     50.000000      8.500000      1.000000   \n",
       "75%     7499.25000      2.124963     64.998500     12.249625      1.499950   \n",
       "max     9999.00000      2.499925     79.997000     15.999250      1.999900   \n",
       "\n",
       "                 cw            cm    LAI_Warren         lidfa         hspot  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.100000      0.100000      4.000000     45.000000      0.075000   \n",
       "std        0.057738      0.057738      2.309517     23.095165      0.014434   \n",
       "min        0.000010      0.000010      0.000400      5.004000      0.050002   \n",
       "25%        0.050005      0.050005      2.000200     25.002000      0.062501   \n",
       "50%        0.100000      0.100000      4.000000     45.000000      0.075000   \n",
       "75%        0.149995      0.149995      5.999800     64.998000      0.087499   \n",
       "max        0.199990      0.199990      7.999600     84.996000      0.099998   \n",
       "\n",
       "       ...            B4            B5            B6            B7  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...      0.036183      0.067180      0.129195      0.154254   \n",
       "std    ...      0.037206      0.040281      0.064657      0.082582   \n",
       "min    ...      0.001574      0.006678      0.014935      0.017731   \n",
       "25%    ...      0.017102      0.038939      0.081280      0.094391   \n",
       "50%    ...      0.022311      0.056801      0.118740      0.139087   \n",
       "75%    ...      0.034553      0.083503      0.167918      0.198793   \n",
       "max    ...      0.200144      0.220337      0.598948      0.793209   \n",
       "\n",
       "                 B8           B8A            B9           B10           B11  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.167312      0.174060      0.171832      0.082803      0.066721   \n",
       "std        0.091378      0.096391      0.092803      0.068753      0.067625   \n",
       "min        0.019403      0.020250      0.020066      0.005064      0.003006   \n",
       "25%        0.100939      0.104070      0.102842      0.035046      0.023089   \n",
       "50%        0.149228      0.154161      0.153295      0.058385      0.039608   \n",
       "75%        0.215923      0.224203      0.224990      0.105039      0.080556   \n",
       "max        0.779937      0.765597      0.778564      0.725032      0.701275   \n",
       "\n",
       "                B12  \n",
       "count  10000.000000  \n",
       "mean       0.042489  \n",
       "std        0.062521  \n",
       "min        0.000884  \n",
       "25%        0.009617  \n",
       "50%        0.013295  \n",
       "75%        0.041685  \n",
       "max        0.530866  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96615c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>LAI_Miller</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>...</th>\n",
       "      <th>QA10</th>\n",
       "      <th>QA20</th>\n",
       "      <th>QA60</th>\n",
       "      <th>cloud_probability</th>\n",
       "      <th>observer_azimuth</th>\n",
       "      <th>observer_zenith</th>\n",
       "      <th>solar_zenith</th>\n",
       "      <th>solar_azimuth</th>\n",
       "      <th>relative_azimuth</th>\n",
       "      <th>LAI_Warren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>902.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1468.145233</td>\n",
       "      <td>1468.145233</td>\n",
       "      <td>2.162702</td>\n",
       "      <td>0.057510</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.136755</td>\n",
       "      <td>0.242238</td>\n",
       "      <td>0.277372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.312639</td>\n",
       "      <td>8.004435</td>\n",
       "      <td>187.459566</td>\n",
       "      <td>5.978706</td>\n",
       "      <td>31.082048</td>\n",
       "      <td>143.645532</td>\n",
       "      <td>170.110579</td>\n",
       "      <td>1.859110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>874.844624</td>\n",
       "      <td>874.844624</td>\n",
       "      <td>2.386208</td>\n",
       "      <td>0.069278</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.069091</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>0.080104</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.092220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.186567</td>\n",
       "      <td>14.095441</td>\n",
       "      <td>77.317421</td>\n",
       "      <td>2.129161</td>\n",
       "      <td>10.165473</td>\n",
       "      <td>16.803007</td>\n",
       "      <td>113.879092</td>\n",
       "      <td>2.008171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.106119</td>\n",
       "      <td>-0.052211</td>\n",
       "      <td>-0.016778</td>\n",
       "      <td>-0.008774</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.024013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.050870</td>\n",
       "      <td>2.910594</td>\n",
       "      <td>15.949376</td>\n",
       "      <td>72.774354</td>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>691.000000</td>\n",
       "      <td>691.000000</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>0.030350</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.221948</td>\n",
       "      <td>4.258278</td>\n",
       "      <td>22.477422</td>\n",
       "      <td>136.262534</td>\n",
       "      <td>45.150719</td>\n",
       "      <td>0.060250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.051702</td>\n",
       "      <td>0.073660</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.117938</td>\n",
       "      <td>0.237712</td>\n",
       "      <td>0.264967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>210.274719</td>\n",
       "      <td>5.618022</td>\n",
       "      <td>28.704009</td>\n",
       "      <td>147.225822</td>\n",
       "      <td>225.739016</td>\n",
       "      <td>1.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2231.250000</td>\n",
       "      <td>2231.250000</td>\n",
       "      <td>4.033750</td>\n",
       "      <td>0.076814</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.121039</td>\n",
       "      <td>0.156133</td>\n",
       "      <td>0.187359</td>\n",
       "      <td>0.282174</td>\n",
       "      <td>0.320273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>256.246612</td>\n",
       "      <td>7.732823</td>\n",
       "      <td>37.373013</td>\n",
       "      <td>154.686462</td>\n",
       "      <td>256.762344</td>\n",
       "      <td>3.591500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3003.000000</td>\n",
       "      <td>3003.000000</td>\n",
       "      <td>10.980000</td>\n",
       "      <td>1.119873</td>\n",
       "      <td>1.096225</td>\n",
       "      <td>1.013699</td>\n",
       "      <td>1.011749</td>\n",
       "      <td>1.043744</td>\n",
       "      <td>1.023045</td>\n",
       "      <td>0.994278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>288.279895</td>\n",
       "      <td>10.032018</td>\n",
       "      <td>58.763682</td>\n",
       "      <td>170.783442</td>\n",
       "      <td>359.986992</td>\n",
       "      <td>7.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  LAI_Miller          B1          B2  \\\n",
       "count   902.000000    902.000000  902.000000  902.000000  902.000000   \n",
       "mean   1468.145233   1468.145233    2.162702    0.057510    0.065264   \n",
       "std     874.844624    874.844624    2.386208    0.069278    0.071170   \n",
       "min       5.000000      5.000000    0.000031   -0.106119   -0.052211   \n",
       "25%     691.000000    691.000000    0.056700    0.024952    0.028020   \n",
       "50%    1447.000000   1447.000000    1.220000    0.047682    0.051702   \n",
       "75%    2231.250000   2231.250000    4.033750    0.076814    0.091615   \n",
       "max    3003.000000   3003.000000   10.980000    1.119873    1.096225   \n",
       "\n",
       "               B3          B4          B5          B6          B7  ...   QA10  \\\n",
       "count  902.000000  902.000000  902.000000  902.000000  902.000000  ...  902.0   \n",
       "mean     0.087519    0.096007    0.136755    0.242238    0.277372  ...    0.0   \n",
       "std      0.069091    0.088034    0.080104    0.078004    0.092220  ...    0.0   \n",
       "min     -0.016778   -0.008774    0.010087    0.019968    0.024013  ...    0.0   \n",
       "25%      0.044474    0.030350    0.079542    0.199428    0.222389  ...    0.0   \n",
       "50%      0.073660    0.069721    0.117938    0.237712    0.264967  ...    0.0   \n",
       "75%      0.121039    0.156133    0.187359    0.282174    0.320273  ...    0.0   \n",
       "max      1.013699    1.011749    1.043744    1.023045    0.994278  ...    0.0   \n",
       "\n",
       "        QA20         QA60  cloud_probability  observer_azimuth  \\\n",
       "count  902.0   902.000000         902.000000        902.000000   \n",
       "mean     0.0   145.312639           8.004435        187.459566   \n",
       "std      0.0   501.186567          14.095441         77.317421   \n",
       "min      0.0     0.000000           0.000000        101.050870   \n",
       "25%      0.0     0.000000           1.000000        104.221948   \n",
       "50%      0.0     0.000000           2.000000        210.274719   \n",
       "75%      0.0     0.000000           6.000000        256.246612   \n",
       "max      0.0  2048.000000          68.000000        288.279895   \n",
       "\n",
       "       observer_zenith  solar_zenith  solar_azimuth  relative_azimuth  \\\n",
       "count       902.000000    902.000000     902.000000        902.000000   \n",
       "mean          5.978706     31.082048     143.645532        170.110579   \n",
       "std           2.129161     10.165473      16.803007        113.879092   \n",
       "min           2.910594     15.949376      72.774354          0.946588   \n",
       "25%           4.258278     22.477422     136.262534         45.150719   \n",
       "50%           5.618022     28.704009     147.225822        225.739016   \n",
       "75%           7.732823     37.373013     154.686462        256.762344   \n",
       "max          10.032018     58.763682     170.783442        359.986992   \n",
       "\n",
       "       LAI_Warren  \n",
       "count  902.000000  \n",
       "mean     1.859110  \n",
       "std      2.008171  \n",
       "min      0.000051  \n",
       "25%      0.060250  \n",
       "50%      1.067000  \n",
       "75%      3.591500  \n",
       "max      7.970000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9fa0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols=(\"lai\", \"LAI_Warren\")\n",
    "feature_cols=['B1', 'B2', 'B3', 'B4', 'B5', 'B6', \\\n",
    "              'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \\\n",
    "              'solar_zenith', 'observer_zenith', 'relative_azimuth']\n",
    "\n",
    "all_cols = feature_cols.copy()\n",
    "all_cols.append(target_cols[1])\n",
    "\n",
    "train_data = (train_df[all_cols].append(validation_df[all_cols])).reindex()\n",
    "test_data = test_df\n",
    "\n",
    "# Train on entire training set\n",
    "X_train = np.array(train_data[feature_cols])\n",
    "y_train = np.array(train_data[target_cols[1]]) \n",
    "X_test = np.array(test_data[feature_cols])\n",
    "y_test = np.array(test_data[target_cols[1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d09eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'solar_zenith', 'observer_zenith', 'relative_azimuth']\n"
     ]
    }
   ],
   "source": [
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdb09b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830743749385262"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "r2_score(y_true=y_test, y_pred=rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d16350a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.129195</td>\n",
       "      <td>0.154254</td>\n",
       "      <td>0.167312</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>0.042489</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024853</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>0.040281</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>0.082582</td>\n",
       "      <td>0.091378</td>\n",
       "      <td>0.096391</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>0.062521</td>\n",
       "      <td>12.991031</td>\n",
       "      <td>2.886896</td>\n",
       "      <td>103.928244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.017731</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>15.002250</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.017477</td>\n",
       "      <td>0.020150</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>0.100939</td>\n",
       "      <td>0.104070</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>0.023089</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>26.251125</td>\n",
       "      <td>2.500250</td>\n",
       "      <td>90.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.039714</td>\n",
       "      <td>0.022311</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>0.118740</td>\n",
       "      <td>0.139087</td>\n",
       "      <td>0.149228</td>\n",
       "      <td>0.154161</td>\n",
       "      <td>0.153295</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.036663</td>\n",
       "      <td>0.059188</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>0.083503</td>\n",
       "      <td>0.167918</td>\n",
       "      <td>0.198793</td>\n",
       "      <td>0.215923</td>\n",
       "      <td>0.224203</td>\n",
       "      <td>0.224990</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.041685</td>\n",
       "      <td>48.748875</td>\n",
       "      <td>7.499750</td>\n",
       "      <td>269.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.139955</td>\n",
       "      <td>0.146249</td>\n",
       "      <td>0.174141</td>\n",
       "      <td>0.200144</td>\n",
       "      <td>0.220337</td>\n",
       "      <td>0.598948</td>\n",
       "      <td>0.793209</td>\n",
       "      <td>0.779937</td>\n",
       "      <td>0.765597</td>\n",
       "      <td>0.778564</td>\n",
       "      <td>0.701275</td>\n",
       "      <td>0.530866</td>\n",
       "      <td>59.997750</td>\n",
       "      <td>9.999500</td>\n",
       "      <td>359.982000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.030222      0.034490      0.048469      0.036183      0.067180   \n",
       "std        0.024853      0.025900      0.030759      0.037206      0.040281   \n",
       "min        0.001430      0.001671      0.003785      0.001574      0.006678   \n",
       "25%        0.017477      0.020150      0.027911      0.017102      0.038939   \n",
       "50%        0.022934      0.026697      0.039714      0.022311      0.056801   \n",
       "75%        0.029193      0.036663      0.059188      0.034553      0.083503   \n",
       "max        0.139955      0.146249      0.174141      0.200144      0.220337   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.129195      0.154254      0.167312      0.174060      0.171832   \n",
       "std        0.064657      0.082582      0.091378      0.096391      0.092803   \n",
       "min        0.014935      0.017731      0.019403      0.020250      0.020066   \n",
       "25%        0.081280      0.094391      0.100939      0.104070      0.102842   \n",
       "50%        0.118740      0.139087      0.149228      0.154161      0.153295   \n",
       "75%        0.167918      0.198793      0.215923      0.224203      0.224990   \n",
       "max        0.598948      0.793209      0.779937      0.765597      0.778564   \n",
       "\n",
       "                 10            11            12            13            14  \n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.066721      0.042489     37.500000      5.000000    180.000000  \n",
       "std        0.067625      0.062521     12.991031      2.886896    103.928244  \n",
       "min        0.003006      0.000884     15.002250      0.000500      0.018000  \n",
       "25%        0.023089      0.009617     26.251125      2.500250     90.009000  \n",
       "50%        0.039608      0.013295     37.500000      5.000000    180.000000  \n",
       "75%        0.080556      0.041685     48.748875      7.499750    269.991000  \n",
       "max        0.701275      0.530866     59.997750      9.999500    359.982000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
